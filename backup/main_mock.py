#!/usr/bin/env python3
"""
å¾®ä¿¡ç¾¤è®¨è®ºæ€»ç»“å·¥å…· - Mock ç‰ˆæœ¬ï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰
åç»­æ‰‹åŠ¨æ›¿æ¢çœŸå®çš„ API è°ƒç”¨
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config_simple import Config
from time_manager import TimeManager
from llm_analyzer_v2 import LLMAnalyzer
from report_generator import ReportGenerator
from wechat_manager_mock import WeChatManager


async def main():
    """ä¸»ç¨‹åº"""
    parser = argparse.ArgumentParser(description='å¾®ä¿¡ç¾¤è®¨è®ºæ€»ç»“å·¥å…· - Mock ç‰ˆæœ¬')
    parser.add_argument('--date', type=str, help='æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºæ˜¨å¤©')
    parser.add_argument('--use-mock', action='store_true', default=True, help='ä½¿ç”¨ Mock æ•°æ®')
    args = parser.parse_args()

    try:
        # éªŒè¯é…ç½®
        Config.validate()
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")

        # è·å–æ˜¨å¤©çš„æ—¥æœŸèŒƒå›´
        yesterday_start, yesterday_end = TimeManager.get_yesterday_range()

        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸ
        if args.date:
            try:
                target_date = datetime.strptime(args.date, "%Y-%m-%d")
                yesterday_start = datetime.combine(target_date.date(), datetime.min.time())
                yesterday_end = datetime.combine(target_date.date(), datetime.max.time())
                print(f"ğŸ“… æŒ‡å®šæ—¥æœŸï¼š{args.date}")
            except ValueError:
                print(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                sys.exit(1)

        print(f"â° æ—¶é—´èŒƒå›´ï¼š{yesterday_start.strftime('%Y-%m-%d %H:%M')} - {yesterday_end.strftime('%H:%M')}")

        # ä½¿ç”¨ Mock æ¨¡å¼
        print("ğŸ“± ä½¿ç”¨ Mock æ¨¡å¼ï¼ˆå¼€å‘æµ‹è¯•ï¼‰")
        wechat_mgr = WeChatManager(use_mock=True)
        await wechat_mgr.login()

        # è·å–æ¶ˆæ¯
        print("ğŸ“¥ æ­£åœ¨è·å–ç¾¤æ¶ˆæ¯...")
        messages = await wechat_mgr.get_messages((yesterday_start, yesterday_end))
        await wechat_mgr.stop()

        if not messages:
            print("âš ï¸  æœªæ‰¾åˆ°æ¶ˆæ¯")
            sys.exit(0)

        print(f"âœ… è·å–åˆ° {len(messages)} æ¡æ¶ˆæ¯")

        # åˆå§‹åŒ– LLM åˆ†æå™¨
        if Config.ZHIPU_API_KEY:
            print("ğŸ¤– ä½¿ç”¨æ™ºè°± AI GLM API")
            analyzer = LLMAnalyzer(Config.ZHIPU_API_KEY, Config.ZHIPU_BASE_URL, model="glm-4-flash")
        elif Config.DEEPSEEK_API_KEY:
            print("ğŸ¤– ä½¿ç”¨ DeepSeek API")
            analyzer = LLMAnalyzer(Config.DEEPSEEK_API_KEY, Config.DEEPSEEK_BASE_URL)
        elif Config.OPENAI_API_KEY:
            print("ğŸ¤– ä½¿ç”¨ OpenAI API")
            analyzer = LLMAnalyzer(Config.OPENAI_API_KEY, "https://api.openai.com/v1", model="gpt-3.5-turbo")
        else:
            print("âŒ æœªé…ç½® LLM API Key")
            sys.exit(1)

        # åˆ†æè®¨è®º
        print("ğŸ¤– æ­£åœ¨åˆ†æè®¨è®ºå†…å®¹...")
        result = analyzer.analyze_discussions(messages, (yesterday_start, yesterday_end))

        if not result.get("success"):
            print(f"âŒ åˆ†æå¤±è´¥: {result.get('error')}")
            sys.exit(1)

        print(f"âœ… åˆ†æå®Œæˆ")

        # ç”ŸæˆæŠ¥å‘Š
        report_gen = ReportGenerator()
        report = report_gen.generate(result, (yesterday_start, yesterday_end))

        # æ‰“å°æŠ¥å‘Š
        report_gen.print_report(report)

        # ä¿å­˜æŠ¥å‘Š
        filepath = report_gen.save_report(report)
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{filepath}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
